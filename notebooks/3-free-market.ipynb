{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from src import foundation\n",
    "from src.foundation.environment_wrapper import RLLibEnvWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"../experiments/free-market-3/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "environment = foundation.make_env_instance(**config.get(\"env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.foundation.agents.BasicMobileAgent at 0x7fa194330cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.get_agent(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = environment.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'p'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_action(agent, mask):\n",
    "    \"\"\"Sample random UNMASKED action(s) for agent.\"\"\"\n",
    "    # Return a list of actions: 1 for each action subspace\n",
    "    if agent.multi_action_mode:\n",
    "        split_masks = np.split(mask, agent.action_spaces.cumsum()[:-1])\n",
    "        return [\n",
    "            np.random.choice(np.arange(len(m_)), p=m_ / m_.sum()) for m_ in split_masks\n",
    "        ]\n",
    "    else:\n",
    "        return np.random.choice(np.arange(agent.action_spaces), p=mask / mask.sum())\n",
    "\n",
    "\n",
    "def sample_random_actions(env, obs):\n",
    "    \"\"\"Samples random UNMASKED actions for each agent in obs.\"\"\"\n",
    "\n",
    "    actions = {\n",
    "        a_idx: sample_random_action(env.get_agent(a_idx), a_obs[\"action_mask\"])\n",
    "        for a_idx, a_obs in obs.items()\n",
    "    }\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projetos/brazilian-ai-economist/src/foundation/base/environment.py:996\u001b[0m, in \u001b[0;36mBaseEnvironment.step\u001b[0;34m(self, actions, seed_state)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components:\n\u001b[0;32m--> 996\u001b[0m     \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscenario_step()\n\u001b[1;32m   1000\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_observations(\n\u001b[1;32m   1001\u001b[0m     flatten_observations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_observations,\n\u001b[1;32m   1002\u001b[0m     flatten_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_masks,\n\u001b[1;32m   1003\u001b[0m )\n",
      "File \u001b[0;32m~/Projetos/brazilian-ai-economist/src/foundation/components.py:1055\u001b[0m, in \u001b[0;36mGather.component_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resource, health \u001b[38;5;129;01min\u001b[39;00m world\u001b[38;5;241m.\u001b[39mlocation_resources(new_r, new_c)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m health \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1055\u001b[0m         n_gathered \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m agent\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbonus_gather_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1056\u001b[0m         agent\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minventory\u001b[39m\u001b[38;5;124m\"\u001b[39m][resource] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_gathered\n\u001b[1;32m   1057\u001b[0m         world\u001b[38;5;241m.\u001b[39mconsume_resource(resource, new_r, new_c)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "actions = sample_random_actions(environment, obs)\n",
    "obs, rew, done, info = environment.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
